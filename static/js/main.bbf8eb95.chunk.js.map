{"version":3,"sources":["utilities.js","App.js","index.js"],"names":["drawRect","detections","ctx","forEach","prediction","x","y","width","height","text","color","Math","floor","random","toString","strokeStyle","font","beginPath","fillStyle","fillText","rect","stroke","App","webcamRef","useRef","canvasRef","useState","spokenObjects","setSpokenObjects","runCoco","a","cocossd","net","console","log","setInterval","detect","speak","message","synth","window","speechSynthesis","utterance","SpeechSynthesisUtterance","current","video","readyState","videoWidth","videoHeight","objects","now","Date","currentObjects","Set","map","obj","class","objectClass","score","toFixed","prev","updatedSpokenObjects","key","has","getContext","useEffect","className","ref","muted","style","position","marginLeft","marginRight","left","right","textAlign","zindex","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"2cAAaA,G,OAAW,SAACC,EAAYC,GAEnCD,EAAWE,SAAQ,SAAAC,GAAc,kBAGDA,EAAU,KAHT,GAGxBC,EAHwB,KAGrBC,EAHqB,KAGlBC,EAHkB,KAGXC,EAHW,KAIzBC,EAAOL,EAAU,MAGjBM,EAAQC,KAAKC,MAAoB,SAAdD,KAAKE,UAAmBC,SAAS,IAC1DZ,EAAIa,YAAc,IAAML,EACxBR,EAAIc,KAAO,aAGXd,EAAIe,YACJf,EAAIgB,UAAY,IAAMR,EACtBR,EAAIiB,SAASV,EAAMJ,EAAGC,GACtBJ,EAAIkB,KAAKf,EAAGC,EAAGC,EAAOC,GACtBN,EAAImB,cCoHOC,MA9Hf,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAYD,iBAAO,MAFZ,EAG6BE,mBAAS,IAHtC,mBAGNC,EAHM,KAGSC,EAHT,KAMPC,EAAO,uCAAG,4BAAAC,EAAA,sEACIC,MADJ,OACRC,EADQ,OAEdC,QAAQC,IAAI,0BAEZC,aAAY,WACVC,EAAOJ,KACN,IANW,2CAAH,qDAUPK,EAAQ,SAACC,GACb,IAAMC,EAAQC,OAAOC,gBACfC,EAAY,IAAIC,yBAAyBL,GAC/CC,EAAMF,MAAMK,IAGRN,EAAM,uCAAG,WAAOJ,GAAP,2BAAAF,EAAA,yDAGkB,qBAAtBP,EAAUqB,SACK,OAAtBrB,EAAUqB,SAC6B,IAAvCrB,EAAUqB,QAAQC,MAAMC,WALb,wBAQLD,EAAQtB,EAAUqB,QAAQC,MAC1BE,EAAaxB,EAAUqB,QAAQC,MAAME,WACrCC,EAAczB,EAAUqB,QAAQC,MAAMG,YAG5CzB,EAAUqB,QAAQC,MAAMtC,MAAQwC,EAChCxB,EAAUqB,QAAQC,MAAMrC,OAASwC,EAGjCvB,EAAUmB,QAAQrC,MAAQwC,EAC1BtB,EAAUmB,QAAQpC,OAASwC,EAlBhB,UAqBWhB,EAAII,OAAOS,GArBtB,QAqBLI,EArBK,OAwBLC,EAAMC,KAAKD,MAGXE,EAAiB,IAAIC,IAAIJ,EAAQK,KAAI,SAACC,GAAD,OAASA,EAAIC,UAGxDP,EAAQ9C,SAAQ,SAACoD,GAAS,IACTE,EAAgBF,EAAvBC,MAGR,IAAK7B,EAAc8B,IAAgBP,EAAMvB,EAAc8B,GAAe,IAAO,CAE3E,IAAMnB,EAAO,uBAAmBmB,EAAnB,kBAAoD,IAAZF,EAAIG,OAAaC,QAAQ,GAAjE,wBACbtB,EAAMC,GAGNV,GAAiB,SAACgC,GAAD,mBAAC,eACbA,GADY,kBAEdH,EAAcP,WAMrBtB,GAAiB,SAACgC,GAChB,IAAMC,EAAuB,GAC7B,IAAK,IAAMC,KAAOF,EACZR,EAAeW,IAAID,KACrBD,EAAqBC,GAAOF,EAAKE,IAGrC,OAAOD,KAIH3D,EAAMuB,EAAUmB,QAAQoB,WAAW,MACzChE,EAASiD,EAAS/C,GA5DP,4CAAH,sDAkEZ,OAFA+D,qBAAU,WAAKpC,MAAW,IAGxB,yBAAKqC,UAAU,OACb,4BAAQA,UAAU,cAChB,kBAAC,IAAD,CACEC,IAAK5C,EACL6C,OAAO,EACPC,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRrE,MAAO,IACPC,OAAQ,OAIZ,4BACE2D,IAAK1C,EACL4C,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRrE,MAAO,IACPC,OAAQ,UCzHpBqE,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,EAAD,OAEFC,SAASC,eAAe,W","file":"static/js/main.bbf8eb95.chunk.js","sourcesContent":["export const drawRect = (detections, ctx) =>{\r\n  // Loop through each prediction\r\n  detections.forEach(prediction => {\r\n\r\n    // Extract boxes and classes\r\n    const [x, y, width, height] = prediction['bbox']; \r\n    const text = prediction['class']; \r\n\r\n    // Set styling\r\n    const color = Math.floor(Math.random()*16777215).toString(16);\r\n    ctx.strokeStyle = '#' + color\r\n    ctx.font = '18px Arial';\r\n\r\n    // Draw rectangles and text\r\n    ctx.beginPath();   \r\n    ctx.fillStyle = '#' + color\r\n    ctx.fillText(text, x, y);\r\n    ctx.rect(x, y, width, height); \r\n    ctx.stroke();\r\n  });\r\n}\r\n","// Import dependencies\r\nimport React, { useRef, useState, useEffect } from \"react\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as cocossd from \"@tensorflow-models/coco-ssd\";\r\nimport Webcam from \"react-webcam\";\r\nimport \"./App.css\";\r\nimport { drawRect } from \"./utilities\";\r\n\r\nfunction App() {\r\n  const webcamRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n  const [spokenObjects, setSpokenObjects] = useState({}); // Tracks last spoken times for each object\r\n\r\n  // Main function\r\n  const runCoco = async () => {\r\n    const net = await cocossd.load();\r\n    console.log(\"Handpose model loaded.\");\r\n    //  Loop and detect hands\r\n    setInterval(() => {\r\n      detect(net);\r\n    }, 10);\r\n  };\r\n\r\n  // Text-to-Speech Function\r\n  const speak = (message) => {\r\n    const synth = window.speechSynthesis;\r\n    const utterance = new SpeechSynthesisUtterance(message);\r\n    synth.speak(utterance);\r\n  };\r\n\r\n  const detect = async (net) => {\r\n    // Check data is available\r\n    if (\r\n      typeof webcamRef.current !== \"undefined\" &&\r\n      webcamRef.current !== null &&\r\n      webcamRef.current.video.readyState === 4\r\n    ) {\r\n      // Get Video Properties\r\n      const video = webcamRef.current.video;\r\n      const videoWidth = webcamRef.current.video.videoWidth;\r\n      const videoHeight = webcamRef.current.video.videoHeight;\r\n\r\n      // Set video width\r\n      webcamRef.current.video.width = videoWidth;\r\n      webcamRef.current.video.height = videoHeight;\r\n\r\n      // Set canvas height and width\r\n      canvasRef.current.width = videoWidth;\r\n      canvasRef.current.height = videoHeight;\r\n\r\n      // Make Detections\r\n      const objects = await net.detect(video);\r\n\r\n      // Get current time\r\n      const now = Date.now();\r\n\r\n      // Create a set of currently detected object classes\r\n      const currentObjects = new Set(objects.map((obj) => obj.class));\r\n\r\n      // Iterate through detected objects\r\n      objects.forEach((obj) => {\r\n        const { class: objectClass } = obj;\r\n\r\n        // Check if this object was spoken about in the last 10 seconds\r\n        if (!spokenObjects[objectClass] || now - spokenObjects[objectClass] > 10000) {\r\n          // Speak the object\r\n          const message = `I detected a ${objectClass} with ${(obj.score * 100).toFixed(2)} percent confidence.`;\r\n          speak(message);\r\n\r\n          // Update the spoken objects state\r\n          setSpokenObjects((prev) => ({\r\n            ...prev,\r\n            [objectClass]: now,\r\n          }));\r\n        }\r\n      });\r\n\r\n      // Remove objects from spokenObjects that are no longer detected\r\n      setSpokenObjects((prev) => {\r\n        const updatedSpokenObjects = {};\r\n        for (const key in prev) {\r\n          if (currentObjects.has(key)) {\r\n            updatedSpokenObjects[key] = prev[key];\r\n          }\r\n        }\r\n        return updatedSpokenObjects;\r\n      });\r\n\r\n      // Draw bounding boxes\r\n      const ctx = canvasRef.current.getContext(\"2d\");\r\n      drawRect(objects, ctx);\r\n    }\r\n  };\r\n\r\n  useEffect(()=>{runCoco()},[]);\r\n\r\n  return (\r\n    <div className=\"App\">\r\n      <header className=\"App-header\">\r\n        <Webcam\r\n          ref={webcamRef}\r\n          muted={true} \r\n          style={{\r\n            position: \"absolute\",\r\n            marginLeft: \"auto\",\r\n            marginRight: \"auto\",\r\n            left: 0,\r\n            right: 0,\r\n            textAlign: \"center\",\r\n            zindex: 9,\r\n            width: 640,\r\n            height: 480,\r\n          }}\r\n        />\r\n\r\n        <canvas\r\n          ref={canvasRef}\r\n          style={{\r\n            position: \"absolute\",\r\n            marginLeft: \"auto\",\r\n            marginRight: \"auto\",\r\n            left: 0,\r\n            right: 0,\r\n            textAlign: \"center\",\r\n            zindex: 8,\r\n            width: 640,\r\n            height: 480,\r\n          }}\r\n        />\r\n      </header>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default App;\r\n","import React from 'react';\r\nimport ReactDOM from 'react-dom';\r\nimport './index.css';\r\nimport App from './App';\r\n\r\nReactDOM.render(\r\n  <React.StrictMode>\r\n    <App />\r\n  </React.StrictMode>,\r\n  document.getElementById('root')\r\n);"],"sourceRoot":""}